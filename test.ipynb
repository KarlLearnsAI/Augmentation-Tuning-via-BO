{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._custom_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compose\n\u001b[1;32m     10\u001b[0m random_mirror \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torchvision/_meta_registrations.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_custom_ops\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'"
     ]
    }
   ],
   "source": [
    "# code in this file is adpated from rpmcruz/autoaugment\n",
    "# https://github.com/rpmcruz/autoaugment/blob/master/transformations.py\n",
    "import random\n",
    "\n",
    "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms.transforms import Compose\n",
    "\n",
    "random_mirror = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def ShearX(img, v):  # [-0.3, 0.3]\n",
    "    assert -0.3 <= v <= 0.3\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
    "\n",
    "\n",
    "def ShearY(img, v):  # [-0.3, 0.3]\n",
    "    assert -0.3 <= v <= 0.3\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert -0.45 <= v <= 0.45\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[0]\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert -0.45 <= v <= 0.45\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    v = v * img.size[1]\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def TranslateXAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert 0 <= v <= 10\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
    "\n",
    "\n",
    "def TranslateYAbs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
    "    assert 0 <= v <= 10\n",
    "    if random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
    "\n",
    "\n",
    "def Rotate(img, v):  # [-30, 30]\n",
    "    assert -30 <= v <= 30\n",
    "    if random_mirror and random.random() > 0.5:\n",
    "        v = -v\n",
    "    return img.rotate(v)\n",
    "\n",
    "\n",
    "def AutoContrast(img, _):\n",
    "    return PIL.ImageOps.autocontrast(img)\n",
    "\n",
    "\n",
    "def Invert(img, _):\n",
    "    return PIL.ImageOps.invert(img)\n",
    "\n",
    "\n",
    "def Equalize(img, _):\n",
    "    return PIL.ImageOps.equalize(img)\n",
    "\n",
    "\n",
    "def Flip(img, _):  # not from the paper\n",
    "    return PIL.ImageOps.mirror(img)\n",
    "\n",
    "\n",
    "def Solarize(img, v):  # [0, 256]\n",
    "    assert 0 <= v <= 256\n",
    "    return PIL.ImageOps.solarize(img, v)\n",
    "\n",
    "\n",
    "def Posterize(img, v):  # [4, 8]\n",
    "    assert 4 <= v <= 8\n",
    "    v = int(v)\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Posterize2(img, v):  # [0, 4]\n",
    "    assert 0 <= v <= 4\n",
    "    v = int(v)\n",
    "    return PIL.ImageOps.posterize(img, v)\n",
    "\n",
    "\n",
    "def Contrast(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
    "\n",
    "\n",
    "def Color(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
    "\n",
    "\n",
    "def Brightness(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Sharpness(img, v):  # [0.1,1.9]\n",
    "    assert 0.1 <= v <= 1.9\n",
    "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
    "\n",
    "\n",
    "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
    "    assert 0.0 <= v <= 0.2\n",
    "    if v <= 0.:\n",
    "        return img\n",
    "\n",
    "    v = v * img.size[0]\n",
    "    return CutoutAbs(img, v)\n",
    "\n",
    "\n",
    "def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
    "    # assert 0 <= v <= 20\n",
    "    if v < 0:\n",
    "        return img\n",
    "    w, h = img.size\n",
    "    x0 = np.random.uniform(w)\n",
    "    y0 = np.random.uniform(h)\n",
    "\n",
    "    x0 = int(max(0, x0 - v / 2.))\n",
    "    y0 = int(max(0, y0 - v / 2.))\n",
    "    x1 = min(w, x0 + v)\n",
    "    y1 = min(h, y0 + v)\n",
    "\n",
    "    xy = (x0, y0, x1, y1)\n",
    "    color = (125, 123, 114)\n",
    "    # color = (0, 0, 0)\n",
    "    img = img.copy()\n",
    "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
    "    return img\n",
    "\n",
    "\n",
    "def SamplePairing(imgs):  # [0, 0.4]\n",
    "    def f(img1, v):\n",
    "        i = np.random.choice(len(imgs))\n",
    "        img2 = PIL.Image.fromarray(imgs[i])\n",
    "        return PIL.Image.blend(img1, img2, v)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def augment_list(for_autoaug=True):  # 16 oeprations and their ranges\n",
    "    l = [\n",
    "        (ShearX, -0.3, 0.3),  # 0\n",
    "        (ShearY, -0.3, 0.3),  # 1\n",
    "        (TranslateX, -0.45, 0.45),  # 2\n",
    "        (TranslateY, -0.45, 0.45),  # 3\n",
    "        (Rotate, -30, 30),  # 4\n",
    "        (AutoContrast, 0, 1),  # 5\n",
    "        (Invert, 0, 1),  # 6\n",
    "        (Equalize, 0, 1),  # 7\n",
    "        (Solarize, 0, 256),  # 8\n",
    "        (Posterize, 4, 8),  # 9\n",
    "        (Contrast, 0.1, 1.9),  # 10\n",
    "        (Color, 0.1, 1.9),  # 11\n",
    "        (Brightness, 0.1, 1.9),  # 12\n",
    "        (Sharpness, 0.1, 1.9),  # 13\n",
    "        (Cutout, 0, 0.2),  # 14\n",
    "        # (SamplePairing(imgs), 0, 0.4),  # 15\n",
    "    ]\n",
    "    if for_autoaug:\n",
    "        l += [\n",
    "            (CutoutAbs, 0, 20),  # compatible with auto-augment\n",
    "            (Posterize2, 0, 4),  # 9\n",
    "            (TranslateXAbs, 0, 10),  # 9\n",
    "            (TranslateYAbs, 0, 10),  # 9\n",
    "        ]\n",
    "    return l\n",
    "\n",
    "\n",
    "augment_dict = {fn.__name__: (fn, v1, v2) for fn, v1, v2 in augment_list()}\n",
    "\n",
    "\n",
    "def get_augment(name):\n",
    "    return augment_dict[name]\n",
    "\n",
    "\n",
    "def apply_augment(img, name, level):\n",
    "    augment_fn, low, high = get_augment(name)\n",
    "    return augment_fn(img.copy(), level * (high - low) + low)\n",
    "\n",
    "\n",
    "class Lighting(object):\n",
    "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
    "\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = torch.Tensor(eigval)\n",
    "        self.eigvec = torch.Tensor(eigvec)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone() \\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
